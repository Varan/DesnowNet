{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0ufmcJXhQ0j"
   },
   "source": [
    "Drive Setup and File Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-drv_VihHg9",
    "outputId": "4d8f4b27-82d6-4d6b-e898-0d8a12cd3a75"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7kIujD4kvhJ"
   },
   "outputs": [],
   "source": [
    "# Create Folder for Datasets\n",
    "# !mkdir /content/drive/MyDrive/Dataset\n",
    "\n",
    "# # Unzip training data\n",
    "# !cp /content/drive/MyDrive/DesnowNet/Snow100K-training.zip /content/drive/MyDrive/Dataset\n",
    "# !zip -FFv /content/drive/MyDrive/Dataset/Snow100K-training.zip --out /content/drive/MyDrive/Dataset/Snow100K-training2.zip # Can't unzip original; -FFv fixes this\n",
    "\n",
    "# Repeat for testing set\n",
    "# !cp /content/drive/MyDrive/DesnowNet/Snow100K-testset.zip /content/drive/MyDrive/Dataset\n",
    "# !zip -FFv /content/drive/MyDrive/Dataset/Snow100K-testset.zip --out /content/drive/MyDrive/Dataset/Snow100K-testset2.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQxXQNDU0caL"
   },
   "outputs": [],
   "source": [
    "# # Storing the dataset locally makes indexing much faster \n",
    "# # than going through Drive for every file\n",
    "# !mkdir /content/Dataset\n",
    "\n",
    "# !cp /content/drive/MyDrive/Dataset/Snow100K-training2.zip /content/Dataset\n",
    "# !unzip -q /content/Dataset/Snow100K-training2.zip -d /content/Dataset\n",
    "# !rm /content/Dataset/Snow100K-training2.zip\n",
    "\n",
    "# !cp /content/drive/MyDrive/Dataset/Snow100K-testset2.zip /content/Dataset\n",
    "# !unzip -q /content/Dataset/Snow100K-testset2.zip -d /content/Dataset\n",
    "# !rm /content/Dataset/Snow100K-testset2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvowrO3WjRgG"
   },
   "outputs": [],
   "source": [
    "dirs = {\n",
    "    'trainset_root': '/content/Dataset/Snow100K-training/all',\n",
    "    'testset_root': '/content/Dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L', # Change last letter to one of \"S\" \"M\" \"L\" to change test set\n",
    "    'checkpoint_exists': True, # Set to False if not loading from a checkpoint\n",
    "    'checkpoint_path_write': '/content/drive/MyDrive/checkpoints',\n",
    "    'checkpoint_path_read': '/content/drive/MyDrive/checkpoints/final_checkpoint.pt'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyqpjtD8ZzuG"
   },
   "source": [
    "Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUQJt-_5gGPl",
    "outputId": "33231272-cc02-4c4c-9f0b-1370ae03f23a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import dill\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8G3THM1ZteP"
   },
   "source": [
    "Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IaV51k3jRf6"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomCrop\n",
    "def DesnowPadCrop(img, size, i, j, padding_mode='symmetric'):\n",
    "    \n",
    "    width, height = TF.get_image_size(img)    \n",
    "    # pad the width if needed\n",
    "    if width < size:\n",
    "        padding = [size - width, 0]\n",
    "        img = TF.pad(img, padding, padding_mode)\n",
    "    # pad the height if needed\n",
    "    if height < size:\n",
    "        padding = [0, size - height]\n",
    "        img = TF.pad(img, padding, padding_mode)\n",
    "    \n",
    "    return TF.crop(img, i, j, size, size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVvNwWJKASiL"
   },
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "class DesnowDataset(data.Dataset):\n",
    "    def __init__(self, main_dir, img_names_list, transform = None):\n",
    "        super(DesnowDataset, self).__init__()\n",
    "        \n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        self.n_imgs = len(img_names_list) \n",
    "        \n",
    "        # os.path.join over string concatenation for OS flexibility\n",
    "        self.gt_imgs = [os.path.join(main_dir, 'gt', img_filename) for img_filename in img_names_list]\n",
    "        self.mask_imgs = [os.path.join(main_dir, 'mask', img_filename) for img_filename in img_names_list]\n",
    "        self.snowy_imgs = [os.path.join(main_dir, 'synthetic', img_filename) for img_filename in img_names_list]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_imgs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # PIL Images for torch.transforms\n",
    "        gt_img = Image.open(self.gt_imgs[idx])\n",
    "        mask_img = Image.open(self.mask_imgs[idx])\n",
    "        snowy_img = Image.open(self.snowy_imgs[idx])\n",
    "        \n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            gt_img = self.transform(gt_img)\n",
    "            mask_img = self.transform(mask_img)\n",
    "            snowy_img = self.transform(snowy_img)\n",
    "            \n",
    "        # Randomly crop and pad if needed\n",
    "        h, w = TF.get_image_size(gt_img)\n",
    "#         i = torch.randint(0, h - 64 + 1, size=(1,)).item()\n",
    "#         j = torch.randint(0, w - 64 + 1, size=(1,)).item()\n",
    "        i = random.randint(0, h-64)\n",
    "        j = random.randint(0, w-64)\n",
    "        gt_img = DesnowPadCrop(gt_img, 64, i, j, padding_mode='symmetric')\n",
    "        mask_img = DesnowPadCrop(mask_img, 64, i, j, padding_mode='symmetric')\n",
    "        snowy_img = DesnowPadCrop(snowy_img, 64, i, j, padding_mode='symmetric')\n",
    "        \n",
    "        # Convert to tensor\n",
    "#         gt_img = transforms.PILToTensor(gt_img)\n",
    "#         mask_img = transforms.PILToTensor(mask_img)\n",
    "#         snowy_img = transforms.PILToTensor(snowy_img)\n",
    "\n",
    "        # Change data type to float32 and standardize manually\n",
    "        # ToTensor() and PILToTensor() unintuitive\n",
    "        gt_arr = np.array(gt_img, dtype=np.float32) / 255\n",
    "        mask_arr = np.array(mask_img, dtype=np.float32) / 255\n",
    "        snowy_arr = np.array(snowy_img, dtype=np.float32) / 255\n",
    "        \n",
    "        # Convert to tensor and return\n",
    "        gt_img = torch.from_numpy(gt_arr).permute((2,0,1))\n",
    "        mask_img = torch.from_numpy(mask_arr).permute((2,0,1))\n",
    "        snowy_img = torch.from_numpy(snowy_arr).permute((2,0,1))\n",
    "\n",
    "        return (gt_img, mask_img, snowy_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCiWrSpPjRf-"
   },
   "source": [
    "Inception v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZQFYFGwjRf_"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/Cadene/pretrained-models.pytorch\n",
    "# Note that the original model is based on classification; the code has been modified to fit our needs\n",
    "# We also change pooling operations to be \"same\" ()\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size=kernel_size, stride=stride,\n",
    "                              padding=padding, bias=False) # verify bias false\n",
    "        self.bn = nn.BatchNorm2d(out_channels,\n",
    "#                                  eps=0.001, # value found in tensorflow\n",
    "                                 eps=1e-05, # default pytroch value\n",
    "                                 momentum=0.1, # default pytorch value\n",
    "                                 affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mixed_3a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_3a, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "        self.conv = BasicConv2d(16, 24, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.maxpool(x)\n",
    "        x1 = self.conv(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_4a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_4a, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(40, 16, kernel_size=1, stride=1),\n",
    "            BasicConv2d(16, 24, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(40, 16, kernel_size=1, stride=1),\n",
    "            BasicConv2d(16, 16, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(16, 16, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(16, 24, kernel_size=(3,3), stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_5a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_5a, self).__init__()\n",
    "        self.conv = BasicConv2d(48, 48, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv(x)\n",
    "        x1 = self.maxpool(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Inception_A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_A, self).__init__()\n",
    "        self.branch0 = BasicConv2d(96, 24, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(96, 16, kernel_size=1, stride=1),\n",
    "            BasicConv2d(16, 24, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(96, 16, kernel_size=1, stride=1),\n",
    "            BasicConv2d(16, 24, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(24, 24, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(96, 24, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Reduction_A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Reduction_A, self).__init__()\n",
    "        self.branch0 = BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(96, 48, kernel_size=1, stride=1),\n",
    "            BasicConv2d(48, 56, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(56, 64, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Inception_B(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_B, self).__init__()\n",
    "        self.branch0 = BasicConv2d(256, 96, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(256, 48, kernel_size=1, stride=1),\n",
    "            BasicConv2d(48, 56, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(56, 64, kernel_size=(7,1), stride=1, padding=(3,0))\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(256, 48, kernel_size=1, stride=1),\n",
    "            BasicConv2d(48, 48, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(48, 56, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(56, 56, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(56, 64, kernel_size=(1,7), stride=1, padding=(0,3))\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(256, 32, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Reduction_B(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Reduction_B, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(256, 48, kernel_size=1, stride=1),\n",
    "            BasicConv2d(48, 48, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(256, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(64, 80, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(80, 80, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Inception_C(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_C, self).__init__()\n",
    "\n",
    "        self.branch0 = BasicConv2d(384, 64, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1_0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "        self.branch1_1a = BasicConv2d(96, 64, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.branch1_1b = BasicConv2d(96, 64, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "\n",
    "        self.branch2_0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "        self.branch2_1 = BasicConv2d(96, 112, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        self.branch2_2 = BasicConv2d(112, 128, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.branch2_3a = BasicConv2d(128, 64, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.branch2_3b = BasicConv2d(128, 64, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(384, 64, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "\n",
    "        x1_0 = self.branch1_0(x)\n",
    "        x1_1a = self.branch1_1a(x1_0)\n",
    "        x1_1b = self.branch1_1b(x1_0)\n",
    "        x1 = torch.cat((x1_1a, x1_1b), 1)\n",
    "\n",
    "        x2_0 = self.branch2_0(x)\n",
    "        x2_1 = self.branch2_1(x2_0)\n",
    "        x2_2 = self.branch2_2(x2_1)\n",
    "        x2_3a = self.branch2_3a(x2_2)\n",
    "        x2_3b = self.branch2_3b(x2_2)\n",
    "        x2 = torch.cat((x2_3a, x2_3b), 1)\n",
    "\n",
    "        x3 = self.branch3(x)\n",
    "\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class InceptionV4(nn.Module):\n",
    "\n",
    "    def __init__(self, num_channels = 3):\n",
    "        super(InceptionV4, self).__init__()\n",
    "        # Special attributes\n",
    "        self.input_space = None\n",
    "        self.input_size = (299, 299, 3)\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        # Modules\n",
    "        self.features = nn.Sequential(\n",
    "            # Change to \"Same\" Convolutions (kernel size 3, stride 1, padding 1)\n",
    "            BasicConv2d(num_channels, 8, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(8, 8, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "            Mixed_3a(),\n",
    "            Mixed_4a(),\n",
    "            Mixed_5a(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Reduction_A(), # Mixed_6a\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Reduction_B(), # Mixed_7a\n",
    "            Inception_C(),\n",
    "            Inception_C(),\n",
    "            Inception_C()\n",
    "        )\n",
    "#         self.last_linear = nn.Linear(1536, num_classes)\n",
    "        \n",
    "#     # Dimensionality reduction from 3D to 1D\n",
    "#     def logits(self, features):\n",
    "#         #Allows image of any size to be processed\n",
    "#         adaptiveAvgPoolWidth = features.shape[2]\n",
    "#         x = F.avg_pool2d(features, kernel_size=adaptiveAvgPoolWidth)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.last_linear(x)\n",
    "#         return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "#         x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnzCVvHwjRgA"
   },
   "source": [
    "Dilation Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15uOJInGjRgB"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/pytorch/vision/blob/main/torchvision/models/segmentation/deeplabv3.py\n",
    "# Pooling and Projection removed; we basically just need Conv2d, BatchNorm2d, and ReLU\n",
    "\n",
    "class ASPPConv(nn.Sequential):\n",
    "    def __init__(self, in_channels: int, out_channels: int, dilation: int) -> None:\n",
    "        modules = [\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        super().__init__(*modules)\n",
    "        \n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels: int, atrous_rates, out_channels: int) -> None: #list instead of List\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        modules.append(\n",
    "            nn.Sequential(nn.Conv2d(in_channels, out_channels, 1, bias=False), nn.BatchNorm2d(out_channels), nn.ReLU())\n",
    "        )\n",
    "\n",
    "        rates = tuple(atrous_rates)\n",
    "        for rate in rates:\n",
    "            modules.append(ASPPConv(in_channels, out_channels, rate))\n",
    "\n",
    "        self.convs = nn.ModuleList(modules)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        _res = []\n",
    "        for conv in self.convs:\n",
    "            _res.append(conv(x))\n",
    "        res = torch.cat(_res, dim=1)\n",
    "        return res "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yh5MuF5sjRgB"
   },
   "source": [
    "Pyramid Maxout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6D4fTTx2jRgB"
   },
   "outputs": [],
   "source": [
    "# Hard coding for beta = 4, specified in the paper\n",
    "class PyramidMaxout_b4(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PyramidMaxout_b4, self).__init__()\n",
    "        \n",
    "        self.prelu = nn.PReLU() # \"weight decay should not be used when learning alpha for good performance\"\n",
    "        self.conv_1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        self.conv_3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        self.conv_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=(1,5), stride=1, padding=(0,2), padding_mode='replicate'),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(5,1), stride=1, padding=(2,0), padding_mode='replicate'))\n",
    "        self.conv_7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=(1,7), stride=1, padding=(0,3), padding_mode='replicate'),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(7,1), stride=1, padding=(3,0), padding_mode='replicate'))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        c1 = self.conv_1(x)\n",
    "        c3 = self.conv_3(x)\n",
    "        c5 = self.conv_5(x)\n",
    "        c7 = self.conv_7(x)\n",
    "        \n",
    "        max_13 = torch.fmax(c1, c3)\n",
    "        max_57 = torch.fmax(c5, c7)\n",
    "        max_all = torch.fmax(max_13, max_57)\n",
    "        \n",
    "        return self.prelu(max_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To9O6rkOjRgC"
   },
   "source": [
    "Translucency Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZgFQQTijRgC"
   },
   "outputs": [],
   "source": [
    "# Generate SE and AE\n",
    "class Rt(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Rt, self).__init__()\n",
    "        \n",
    "        self.SE = PyramidMaxout_b4(in_channels, 1) # z hat\n",
    "        self.AE = PyramidMaxout_b4(in_channels, 3) # a\n",
    "        \n",
    "    def forward(self, ft, x):\n",
    "        a = self.AE(ft)\n",
    "        z = self.SE(ft)\n",
    "        z_broadcasted = torch.cat((z, z, z), dim = 1)\n",
    "\n",
    "        y_prime = (x - a * z_broadcasted) / (1 + 1e-5 - z_broadcasted)  # Case 1\n",
    "        y_prime[z_broadcasted >= 1] = x[z_broadcasted >= 1]             # Case 2\n",
    "\n",
    "        fc = torch.cat([y_prime, z_broadcasted, a], dim = 1)\n",
    "    \n",
    "        return z_broadcasted, y_prime, fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5xgm_0djRgC"
   },
   "source": [
    "Residual Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3sUflZgjRgC"
   },
   "outputs": [],
   "source": [
    "# Hard coding for beta = 4, specified in the paper\n",
    "class PyramidSum_b4(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PyramidSum_b4, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        self.conv_3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, padding_mode='replicate')\n",
    "        self.conv_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=(1,5), stride=1, padding=(0,2), padding_mode='replicate'),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(5,1), stride=1, padding=(2,0), padding_mode='replicate'))\n",
    "        self.conv_7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=(1,7), stride=1, padding=(0,3), padding_mode='replicate'),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(7,1), stride=1, padding=(3,0), padding_mode='replicate'))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        c1 = self.conv_1(x)\n",
    "        c3 = self.conv_3(x)\n",
    "        c5 = self.conv_5(x)\n",
    "        c7 = self.conv_7(x)\n",
    "        \n",
    "        return c1 + c3 + c5 + c7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArDporYOjRgF"
   },
   "source": [
    "Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wat-OdOfjRgF"
   },
   "outputs": [],
   "source": [
    "# P_n denotes the max-pooling operation with kernel size nxn and stride nxn for non-overlapped pooling\n",
    "\n",
    "class PyramidLossPool(nn.Sequential):\n",
    "    def __init__(self, n: int) -> None:\n",
    "        modules = [\n",
    "            nn.MaxPool2d(kernel_size=n, stride=n)\n",
    "        ]\n",
    "        super().__init__(*modules)\n",
    "        \n",
    "\n",
    "class PyramidLoss(nn.Module):\n",
    "    def __init__(self, tau: int) -> None: #list instead of List\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "\n",
    "        sizes = tuple(range(1, tau*2, 2))\n",
    "        for n in sizes:\n",
    "            modules.append(PyramidLossPool(n))\n",
    "\n",
    "        self.pools = nn.ModuleList(modules)\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        cum_loss = 0\n",
    "        for pools in self.pools:\n",
    "            cum_loss += self.mse(pools(x), pools(y))\n",
    "        \n",
    "        return cum_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilD7kCZejRgF"
   },
   "source": [
    "Xavier Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWwKyvzljRgF"
   },
   "outputs": [],
   "source": [
    "# Adapted (directly) from https://gist.github.com/jeasinema/ed9236ce743c8efaf30fa2ff732749f5\n",
    "def weight_init(m):\n",
    "    '''\n",
    "    Usage:\n",
    "        model = Model()\n",
    "        model.apply(weight_init)\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        init.normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.Conv3d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose1d):\n",
    "        init.normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose3d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm3d):\n",
    "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.LSTMCell):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.GRU):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.GRUCell):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wEejMxujRgF"
   },
   "source": [
    "Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSe6JCVejRgG"
   },
   "outputs": [],
   "source": [
    "class DesnowNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DesnowNet, self).__init__()\n",
    "        \n",
    "        self.Dt = InceptionV4(3)\n",
    "        self.DP = ASPP(384, [2,4,8,16], 192)\n",
    "        self.Dr = InceptionV4(9)\n",
    "        self.Rt = Rt(960)\n",
    "        self.Rr = PyramidSum_b4(384, 3)\n",
    "        \n",
    "        # We have to initialize the submodules\n",
    "        self.Dt.apply(weight_init)\n",
    "        self.DP.apply(weight_init)\n",
    "        self.Dr.apply(weight_init)\n",
    "        self.Rt.apply(weight_init)\n",
    "        self.Rr.apply(weight_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        Dt_out = self.Dt(x)\n",
    "        ft = self.DP(Dt_out)\n",
    "        z_hat, y_prime, fc = self.Rt(ft, x)\n",
    "        fr = self.Dr(fc)\n",
    "        r = self.Rr(fr)\n",
    "        y_hat = y_prime + r\n",
    "        return y_hat, y_prime, z_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJYvEdIvjRgG"
   },
   "source": [
    "Initialize Datasets and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCUzYAEsjRgG"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/image_captioning/train.py\n",
    "\n",
    "# img_paths = dill.load(open('/content/drive/MyDrive/Dataset/test_list_L', 'rb'))\n",
    "img_paths = os.listdir(os.path.join(dirs['trainset_root'], 'gt'))\n",
    "trainset = DesnowDataset(main_dir = dirs['trainset_root'], img_names_list = img_paths)\n",
    "trainset_dataloader = data.DataLoader(dataset=trainset,\n",
    "                                     batch_size = 5,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=False,\n",
    "                                     pin_memory=True)\n",
    "\n",
    "# test_paths = dill.load(open('/content/drive/MyDrive/Dataset/test_list_L', 'rb'))\n",
    "test_paths = os.listdir(os.path.join(dirs['testset_root'], 'gt'))\n",
    "testset = DesnowDataset(main_dir = dirs['testset_root'], img_names_list = test_paths)\n",
    "testset_dataloader = data.DataLoader(dataset=testset,\n",
    "                                    batch_size = 5,\n",
    "                                    shuffle=True,\n",
    "                                    drop_last=False,\n",
    "                                    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4N4UvpMjRgG"
   },
   "outputs": [],
   "source": [
    "model = DesnowNet()\n",
    "model.to(device)\n",
    "\n",
    "# --- Build optimizer --- #\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr = 3e-5,\n",
    "                       weight_decay = 5e-4 #λw; this accounts for the final term of Eq (8) \n",
    "                      )\n",
    "\n",
    "# --- Define the loss function (criterion) --- #\n",
    "criterion = PyramidLoss(tau = 4).to(device) # Tau is unspecified; consider using 4 similar to beta in Pyramid Sum/Max\n",
    "MSE = nn.MSELoss().to(device)     # For PSNR calculation (consdier also SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1m2Ur6djRgH"
   },
   "source": [
    "Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfhR4z-hjRgH",
    "outputId": "68a97daa-aece-4cc9-941b-d96bc689f8c0"
   },
   "outputs": [],
   "source": [
    "# Remember to set dirs['checkpoint_exists'] to True after the first epoch\n",
    "if dirs['checkpoint_exists']:\n",
    "    checkpoint = torch.load(dirs['checkpoint_path_read'], map_location=device)\n",
    "    model.load_state_dict(checkpoint['model state'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer state'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    # loss = checkpoint['Train loss']\n",
    "    print(\"Loaded epoch\", start_epoch)\n",
    "else:\n",
    "    start_epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrbaZLjUjRgH"
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429,
     "referenced_widgets": [
      "9a5121a9e6954318bcfad3b860059c2d",
      "70a9cf455a884e8784be35fcb97fbea4",
      "533eba576fb8449e8400f377ee3bf7b8",
      "bc07e40baf1f42a7a940376e2bd62d24",
      "4141c1fd79794582a3f39839fe5fa812",
      "0635ef98ffd2420387946126cdb76701",
      "f77c265d8e914b7293af94b1e915ebcb",
      "35c1ae088dd9430495a3bdaaf8fdcd15",
      "4d9161160b104d19a375b86077d85789",
      "481442292bb24ad694efbab6ffe9fd3a",
      "826c43c5c5914a9d962895db2152c2fa"
     ]
    },
    "id": "0haGgbDKjRgH",
    "outputId": "143c5ffa-25aa-45a3-ee9f-a62d18d17723"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "\n",
    "for epoch in range(start_epoch + 1, 999): # Will have to stop manually\n",
    "    running_loss = 0\n",
    "    avg_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    training_loop = tqdm(trainset_dataloader, leave=False, position=0)\n",
    "    for iter_idx, img_data in enumerate(training_loop):\n",
    "\n",
    "        # Instantiate data\n",
    "        gt_img, mask_img, snowy_img = img_data\n",
    "        gt_img, mask_img, snowy_img = gt_img.to(device), mask_img.to(device), snowy_img.to(device)\n",
    "    \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Make predictions for this batch\n",
    "        y_hat, y_prime, z_hat = model(snowy_img)\n",
    "    \n",
    "        # Compute the loss and its gradients\n",
    "        loss = criterion(y_prime, gt_img) + criterion(y_hat, gt_img) + 3 * criterion(z_hat, mask_img)\n",
    "        running_loss += loss.item()\n",
    "        avg_loss = running_loss / (iter_idx + 1)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Training Loss\", avg_loss)\n",
    "         \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model state': model.state_dict(),\n",
    "        'optimizer state': optimizer.state_dict(),\n",
    "        'Train loss': sum(epoch_loss)/len(epoch_loss)},\n",
    "        os.path.join(dirs['checkpoint_path_write'], f'model_epoch_{epoch}.pt'))\\\n",
    "\n",
    "    print(\"Saved state at epoch\", epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkceFDZCTft8"
   },
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429,
     "referenced_widgets": [
      "6a000f1097794fcb87616dde47a49a4a",
      "3a85a6b94fc34de8905799f70616b036",
      "ae5f18576a86484bbc7e1859ba80200c",
      "a75debc862114f56840228a6cca5a5c4",
      "0e0abf21d8c94e24b1325e97270b2119",
      "f6ff5eac63c8428dbcfdde8deb7c6f35",
      "1b82a8d6236c4df28b3feeb119927bfb",
      "ed19ae7e07434f62aca80a43a4e45131",
      "fdb6f7bf2e8c46399e88b0dece895465",
      "9a2af6cb0d5c49ccbbae2de6bd103005",
      "d686437b29204e6cb6f8aaf98a942a4e"
     ]
    },
    "id": "2E1dbr4ZfpFc",
    "outputId": "1733b555-dc85-429c-d76a-4e0db7928444"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "running_psnr = 0\n",
    "avg_psnr = 0\n",
    "    \n",
    "test_loop = tqdm(testset_dataloader, leave=False, position=0)\n",
    "for iter_idx, img_data in enumerate(test_loop):\n",
    "\n",
    "    # Forward propagation\n",
    "    gt_img, mask_img, snowy_img = img_data\n",
    "    gt_img, mask_img, snowy_img = gt_img.to(device), mask_img.to(device), snowy_img.to(device)\n",
    "    y_hat, y_prime, z_hat = model(snowy_img)\n",
    "            \n",
    "    # Clip output\n",
    "    y_hat = torch.clamp(y_hat, min=0, max=1)\n",
    "            \n",
    "    # Compute MSE and PSNR\n",
    "    loss = MSE(y_hat, gt_img)\n",
    "    running_psnr += (10 * np.log10(1/loss.item()))\n",
    "    avg_psnr = running_psnr / (iter_idx + 1)\n",
    "            \n",
    "print(\"PSNR: \", avg_psnr)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DesnowNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0635ef98ffd2420387946126cdb76701": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e0abf21d8c94e24b1325e97270b2119": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b82a8d6236c4df28b3feeb119927bfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35c1ae088dd9430495a3bdaaf8fdcd15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a85a6b94fc34de8905799f70616b036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6ff5eac63c8428dbcfdde8deb7c6f35",
      "placeholder": "​",
      "style": "IPY_MODEL_1b82a8d6236c4df28b3feeb119927bfb",
      "value": "  0%"
     }
    },
    "4141c1fd79794582a3f39839fe5fa812": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "481442292bb24ad694efbab6ffe9fd3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d9161160b104d19a375b86077d85789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "533eba576fb8449e8400f377ee3bf7b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35c1ae088dd9430495a3bdaaf8fdcd15",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d9161160b104d19a375b86077d85789",
      "value": 0
     }
    },
    "6a000f1097794fcb87616dde47a49a4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a85a6b94fc34de8905799f70616b036",
       "IPY_MODEL_ae5f18576a86484bbc7e1859ba80200c",
       "IPY_MODEL_a75debc862114f56840228a6cca5a5c4"
      ],
      "layout": "IPY_MODEL_0e0abf21d8c94e24b1325e97270b2119"
     }
    },
    "70a9cf455a884e8784be35fcb97fbea4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0635ef98ffd2420387946126cdb76701",
      "placeholder": "​",
      "style": "IPY_MODEL_f77c265d8e914b7293af94b1e915ebcb",
      "value": "  0%"
     }
    },
    "826c43c5c5914a9d962895db2152c2fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a2af6cb0d5c49ccbbae2de6bd103005": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a5121a9e6954318bcfad3b860059c2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70a9cf455a884e8784be35fcb97fbea4",
       "IPY_MODEL_533eba576fb8449e8400f377ee3bf7b8",
       "IPY_MODEL_bc07e40baf1f42a7a940376e2bd62d24"
      ],
      "layout": "IPY_MODEL_4141c1fd79794582a3f39839fe5fa812"
     }
    },
    "a75debc862114f56840228a6cca5a5c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a2af6cb0d5c49ccbbae2de6bd103005",
      "placeholder": "​",
      "style": "IPY_MODEL_d686437b29204e6cb6f8aaf98a942a4e",
      "value": " 0/3361 [00:00&lt;?, ?it/s]"
     }
    },
    "ae5f18576a86484bbc7e1859ba80200c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed19ae7e07434f62aca80a43a4e45131",
      "max": 3361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fdb6f7bf2e8c46399e88b0dece895465",
      "value": 0
     }
    },
    "bc07e40baf1f42a7a940376e2bd62d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_481442292bb24ad694efbab6ffe9fd3a",
      "placeholder": "​",
      "style": "IPY_MODEL_826c43c5c5914a9d962895db2152c2fa",
      "value": " 0/10000 [00:00&lt;?, ?it/s]"
     }
    },
    "d686437b29204e6cb6f8aaf98a942a4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed19ae7e07434f62aca80a43a4e45131": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6ff5eac63c8428dbcfdde8deb7c6f35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f77c265d8e914b7293af94b1e915ebcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdb6f7bf2e8c46399e88b0dece895465": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
